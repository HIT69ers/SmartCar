#!/usr/bin/env python
# coding:utf-8

# åŠ è½½æ‰€éœ€æ¨¡å—
import rosnode
import numpy as np
import rospy
import time
import os
import sys
import cv2
from std_msgs.msg import String
from std_msgs.msg import Int32
from pathlib import Path
from photo_and_qr.srv import Greeting,GreetingRequest,GreetingResponse
from geometry_msgs.msg import Twist

parkingNum = 1

def Twist_Pub(pub, lx, ly, lz, ax, ay, az):
    twist = Twist()
    twist.linear.x = lx
    twist.linear.y = ly
    twist.linear.z = lz
    twist.angular.x = ax
    twist.angular.y = ay
    twist.angular.z = az
    pub.publish(twist)

def Server_Srv():
    rospy.init_node("PhotoAndQR_Server")
    s = rospy.Service("greetings", Greeting, Handle_Function)
    rospy.loginfo("qr Server is online ğŸ¥²")
    # é˜»å¡è‡³ç¨‹åºç»“æŸ
    rospy.spin()

def Handle_Function(req):
    print('cvDICT  å¯åŠ¨')
    cvDICT()
    return GreetingResponse("Finished!")

def cvDICT():
    global parkingNum
    dist_matrix = np.array([-0.323074221732616, 0.103243450673514, 0, 0, 0])
    camera_matrix = np.array([[431.416676013977, 0., 321.918201475723], [0., 433.136389691851, 229.497858115603], [0., 0., 1.]])
    pub_cmd = rospy.Publisher('/cmd_vel', Twist, queue_size = 1)
    cap = cv2.VideoCapture(0)
    print("è·å–åˆ°ç”»é¢")
    start_time_outer = rospy.Time.now().to_sec()
    # while True:
    while rospy.Time.now().to_sec() - start_time_outer < 0.9:
        ret, frame = cap.read()
        # cv2.waitKey(20)
        # å›¾åƒå·¦å³é¢ å€’
        frame = cv2.flip(frame, 1)  
        width, height = 480, 600
        # è¯»å–æ‘„åƒå¤´ç”»é¢
        # çº æ­£ç•¸å˜
        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_matrix, (height, width), 0, (height, width))
        dst = cv2.undistort(frame, camera_matrix, dist_matrix, None, newcameramtx)
        x, y, width, height = roi
        dst = dst[y:y + height, x:x + width]
        frame = dst
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)
        parameters = cv2.aruco.DetectorParameters_create()
        # ä½¿ç”¨aruco.detectMarkers()å‡½æ•°å¯ä»¥æ£€æµ‹åˆ°markerï¼Œè¿”å›IDå’Œæ ‡å¿—æ¿çš„4ä¸ªè§’ç‚¹åæ ‡
        (corners, ids, rejectedImgPoints) = cv2.aruco.detectMarkers(gray, aruco_dict, parameters = parameters)
        if ids is not None:
            break
    else:
        return
    print("ready to move!")
    for markerID, markerCorner in zip(ids,corners):
        if markerID == [parkingNum]:
            # rvecä¸ºæ—‹è½¬çŸ©é˜µï¼Œtvecä¸ºä½ç§»çŸ©é˜µ
            rvec, tvec, _ = cv2.aruco.estimatePoseSingleMarkers(markerCorner, 0.05, camera_matrix, dist_matrix)
            # get rid of that nasty numpy value array error
            (rvec - tvec).any()  
            # è·ç¦»ä¼°è®¡
            distance = tvec[0][0][2] * 178.2 + 0.6
            if distance >= 17.5:
                start_time = rospy.Time.now().to_sec()
                running_time = rospy.Time.now().to_sec() - start_time
                set_time = (distance - 16) / 100 / 0.5 - 0.03
                while running_time < set_time:
                    running_time = rospy.Time.now().to_sec() - start_time
                    Twist_Pub(pub_cmd, 0.5, -0.2, 0.0, 0.0, 0.0, 0.0)
                    # print(">>> my step")
                print('distance:',distance)
                print('settime:',set_time)
                rospy.loginfo("Have headed!Arrived!")
            else:
                rospy.loginfo("Not need to head!Arrived!")

if __name__ == "__main__":
    
    Server_Srv()
